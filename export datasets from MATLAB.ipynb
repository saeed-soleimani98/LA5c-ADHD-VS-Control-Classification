{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a9eacdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rest_dataset.csv saved! Shape: (162, 17)\n",
      "âœ… SCAP_dataset.csv saved! Shape: (162, 17)\n",
      "âœ… SST_Go_dataset.csv saved! Shape: (160, 17)\n",
      "âœ… SST_Stop_dataset.csv saved! Shape: (160, 17)\n",
      "âœ… SST_Diff_dataset.csv saved! Shape: (160, 17)\n",
      "\n",
      "ðŸŽ‰ All datasets successfully created with real ROI names!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "BASE_DIR = r'G:\\results'   # Update this if needed\n",
    "MAT_FILE_FOR_NAMES = r'G:\\results\\conn_project01_Rest\\firstlevel\\RRC_01\\resultsROI_Condition001.mat'\n",
    "PROJECTS = {\n",
    "    'Rest': r'conn_project01_Rest\\firstlevel\\RRC_01',\n",
    "    'SCAP': r'conn_project02_Scap\\firstlevel\\RRC_01',\n",
    "    'SST_Go': r'conn_project03_Stopsignal\\firstlevel\\RRC_01',\n",
    "    'SST_Stop': r'conn_project03_Stopsignal\\firstlevel\\RRC_01'\n",
    "}\n",
    "N_ROIS = 6\n",
    "\n",
    "# === STEP 1: Extract Real ROI Names ===\n",
    "roi_mat = sio.loadmat(MAT_FILE_FOR_NAMES)\n",
    "roi_names_raw = roi_mat['names']\n",
    "\n",
    "roi_names = []\n",
    "for i in range(roi_names_raw.shape[1]):\n",
    "    roi_names.append(str(roi_names_raw[0, i][0]))\n",
    "\n",
    "# Generate feature names based on ROI pairs\n",
    "feature_names = []\n",
    "for i in range(N_ROIS):\n",
    "    for j in range(i+1, N_ROIS):\n",
    "        feature_names.append(f\"{roi_names[i]}_to_{roi_names[j]}\")\n",
    "\n",
    "# Clean feature names\n",
    "feature_names = [name.replace(' ', '_').replace('-', '_') for name in feature_names]\n",
    "\n",
    "# === FUNCTION TO DEFINE LABELS ===\n",
    "def get_label(subject_id, condition):\n",
    "    if condition in ['Rest', 'SCAP']:\n",
    "        return 0 if subject_id <= 121 else 1\n",
    "    elif condition in ['SST_Go', 'SST_Stop']:\n",
    "        return 0 if subject_id <= 120 else 1\n",
    "\n",
    "# === FUNCTION TO EXTRACT FEATURES ===\n",
    "def extract_features(mat_file):\n",
    "    data = sio.loadmat(mat_file)\n",
    "    Z = data['Z']\n",
    "    features = Z[np.triu_indices(N_ROIS, k=1)]\n",
    "    return features\n",
    "\n",
    "# === STEP 2: Generate Regular Datasets ===\n",
    "all_sst_go = {}\n",
    "all_sst_stop = {}\n",
    "\n",
    "for condition, path in PROJECTS.items():\n",
    "    rows = []\n",
    "    full_path = os.path.join(BASE_DIR, path)\n",
    "    \n",
    "    for file in os.listdir(full_path):\n",
    "        if file.startswith('resultsROI_Subject') and file.endswith('.mat'):\n",
    "            if 'SST' in condition:\n",
    "                if condition == 'SST_Go' and 'Condition001' not in file:\n",
    "                    continue\n",
    "                if condition == 'SST_Stop' and 'Condition002' not in file:\n",
    "                    continue\n",
    "            else:\n",
    "                if 'Condition001' not in file:\n",
    "                    continue\n",
    "\n",
    "            subject_id = int(file.split('_')[1].replace('Subject', ''))\n",
    "            label = get_label(subject_id, condition)\n",
    "            features = extract_features(os.path.join(full_path, file))\n",
    "\n",
    "            row = [subject_id] + list(features) + [label]\n",
    "            rows.append(row)\n",
    "\n",
    "            # Store for SST difference\n",
    "            if condition == 'SST_Go':\n",
    "                all_sst_go[subject_id] = features\n",
    "            if condition == 'SST_Stop':\n",
    "                all_sst_stop[subject_id] = features\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=['Subject_ID'] + feature_names + ['Label'])\n",
    "    df.to_csv(f\"{condition}_dataset.csv\", index=False)\n",
    "    print(f\"âœ… {condition}_dataset.csv saved! Shape: {df.shape}\")\n",
    "\n",
    "# === STEP 3: Generate SST_Diff Dataset ===\n",
    "diff_rows = []\n",
    "common_subjects = set(all_sst_go.keys()) & set(all_sst_stop.keys())\n",
    "\n",
    "for subject_id in sorted(common_subjects):\n",
    "    diff_features = all_sst_stop[subject_id] - all_sst_go[subject_id]\n",
    "    label = get_label(subject_id, 'SST_Go')  # Same label for both phases\n",
    "    row = [subject_id] + list(diff_features) + [label]\n",
    "    diff_rows.append(row)\n",
    "\n",
    "df_diff = pd.DataFrame(diff_rows, columns=['Subject_ID'] + feature_names + ['Label'])\n",
    "df_diff.to_csv(\"SST_Diff_dataset.csv\", index=False)\n",
    "print(f\"âœ… SST_Diff_dataset.csv saved! Shape: {df_diff.shape}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ All datasets successfully created with real ROI names!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97dfb949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned combined dataset saved: G:\\csv_outputs\\Combined_4Condition_Cleaned.csv\n",
      "Subjects retained: 159, Features: 60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "DATASET_DIR = r'G:\\csv_outputs'\n",
    "output_file = os.path.join(DATASET_DIR, 'Combined_4Condition_Cleaned.csv')\n",
    "conditions = ['Rest', 'SCAP', 'SST_Go', 'SST_Stop']\n",
    "\n",
    "datasets = {}\n",
    "for cond in conditions:\n",
    "    df = pd.read_csv(os.path.join(DATASET_DIR, f\"{cond}_dataset.csv\"))\n",
    "\n",
    "    # Rename feature columns\n",
    "    feature_cols = [col for col in df.columns if col not in ['Subject_ID', 'Label']]\n",
    "    df.rename(columns={col: f\"{cond}_{col}\" for col in feature_cols}, inplace=True)\n",
    "    df.rename(columns={'Label': f'{cond}_Label'}, inplace=True)\n",
    "\n",
    "    datasets[cond] = df\n",
    "\n",
    "# Merge all on Subject_ID\n",
    "merged = datasets['Rest']\n",
    "for cond in ['SCAP', 'SST_Go', 'SST_Stop']:\n",
    "    merged = pd.merge(merged, datasets[cond], on='Subject_ID', how='inner')\n",
    "\n",
    "# Keep only rows where all labels match\n",
    "merged = merged[\n",
    "    (merged['Rest_Label'] == merged['SCAP_Label']) &\n",
    "    (merged['Rest_Label'] == merged['SST_Go_Label']) &\n",
    "    (merged['Rest_Label'] == merged['SST_Stop_Label'])\n",
    "].copy()\n",
    "\n",
    "# Drop all but one Label\n",
    "merged['Label'] = merged['Rest_Label']\n",
    "merged.drop(columns=['Rest_Label', 'SCAP_Label', 'SST_Go_Label', 'SST_Stop_Label'], inplace=True)\n",
    "\n",
    "# Save final dataset\n",
    "merged.to_csv(output_file, index=False)\n",
    "print(f\"âœ… Cleaned combined dataset saved: {output_file}\")\n",
    "print(f\"Subjects retained: {merged.shape[0]}, Features: {merged.shape[1] - 2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
